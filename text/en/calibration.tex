\chapter{Calibration}

Our goal to create a system which does not need any information about a
position of the cameras. Since we do not know how far away cameras are, nor
angles, we firstly use calibration to obtain this information.

By calibrating cameras with a well describable pattern, we can obtain
information about the single camera, like what distortion its lens cause, or
how to world points are projected to an image plane of the camera.

After discovering these parameters for both cameras, we will continue on stereo
calibration. Stereo calibration will provide us information about their
position in space relative to each other.

For these calibration processes, we use algorithms implemented in OpenCV.
Therefore, we provide only a short overview of the process, and we describe
only results obtained from calibration essential to us.

\section{Intrinsic parameters}

Each camera type is different. Moreover, each camera of a specific type is
different due to a manufacturing process. Therefore we introduce intrinsic
camera parameters, which helps us a model of the camera precisely.

Intrinsic camera parameters define a transform between a world coordinates and
the coordinates within an image plane (in pixels). Physical attributes of the
camera influence this transformation.

These parameters include focal length, a position of the principal point and
distortion coefficients. All these parameters are needed to get a correct
transformation between the point in the space and the point at the image plane.
Sometimes even more parameters are used for a better description of the model
of the camera.

\subsection{Camera matrix} Camera matrix will provide us a transformation from
world coordinates (with the origin in the camera) to image plane coordinates
(seen in the image taken from the camera). If the coordinates in 3D are
available, we can obtain 2D coordinates by simple multiplication by camera
matrix.

As a next step, we describe camera matrix obtained by OpenCV calibration
procedure.

The approach of the camera matrix which OpenCV use is to represent it as a
matrix $3\times3$ matrix in the following format: 

\[
\begin{pmatrix}
	f_x 	& 0 	& c_x \\
	0	& f_y	& c_y \\
	0	& 0	& 1
\end{pmatrix}
\]

Where $f_x$, $f_y$ denotes focal length expressed in pixel units. It is usually
to introduce two of them, separately for both axes, since pixels usually are
not a perfect square but rather rectangle. Therefore same focal length has
different length in pixel units over a given ax.

Parameters $c_x$ and $c_y$ defines coordinates in image plane where the
principal point intersects the image. It should be the center of the image, but
assembling process of the camera might cause a small displacement.

\subsection{Distortion coefficients}

Cameras are equipped with the lenses to provide more light. Therefore the lens
causes various distortions. Fish-Eye lenses are known for their distortion.
Even web camera lens has distortion, but not so visible as the camera with a
fish-eye lens. It is important to correct these distortions.

Two distortion types cause a significant effect on the image. The first one is
the radial distortion, creating barrel effect and the second one tangential.

The radial distortion is caused by the camera lens (the effect of radial
distortion is displayed in the image \ref{fig:distortion}). It can usually be
described by three parameters. Highly distorted images (like from fish-eye)
often need more parameters. Since our system use webcameras, we will use only
three parameters.

In the ideal camera, the lens would be placed parallel to the chip. Since such
precision, while assembling process is not possible, tangential distortion
arises. For this distortion, we use two parameters.

We describe both distortion effects by five parameters. More about the meaning
of the parameters could be found in \ref{learning-opencv}.

\begin{figure}
	\begin{subfigure}[b]{0.48\linewidth}
		\includegraphics[width=\linewidth]{img/chessboard/7x8chessboard-positivedistortion}
		\caption{Effect of positive radial distortion}
	\end{subfigure}
	\begin{subfigure}[b]{0.48\linewidth}
		\includegraphics[width=\linewidth]{img/chessboard/7x8chessboard-negativedistortion}
		\caption{Effect of negative radial distortion}
	\end{subfigure}
	\caption{Effects of lens distortion on the image of the chessboard}
	\label{fig:distortion}
\end{figure}

We can now describe transformation process in one camera by multiplication by
camera matrix and then correcting the results by distortion coefficients. With
these parameters, we can continue on stereo calibration.

\section{Stereo calibration}

After performing a calibration of both cameras, we also need information about
their relative position to each other. This position can be described by six
parameters, three as an angle around each ax to rotate and three for
translation vector.

Stereo calibration routine in OpenCV can also perform monocalibration for both
cameras, but we pre-calibrate cameras on itself for better precision and better
convergence of the algorithm.

Stereo calibration routine will provide more information. For this thesis is
only important previously mentioned rotation matrix and translation vector.

\section{Calibration process}

Now we know what we expect from calibration process. However, we still need to
perform this calibration. For the calibration, we use an object which is well
known and easy to describe. In OpenCV is commonly used chessboard, since it is
a planar object (easy to reproduce by printing) and well described. OpenCV also
provides methods for automatic finding chessboard in the picture, so no human
intervention is needed to select chessboard corners from the image (an example
of the chessboard is provided in a figure \ref{fig:chessboard}). Therefore, we
also use chessboard pattern for calibration.

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{img/chessboard/7x8chessboard}
	\caption{Example of $7\times8$ chessboard used for the calibration}
	\label{fig:chessboard}
\end{figure}

\subsection{How many images?} Now we know, we can use a chessboard to calibrate
our cameras. However, still, the question of how many images are needed for the
calibration remains. We discuss only the images where the full chessboard is
found. For enough information from each image, we need a chessboard with at
least $3\times3$ inner corners. It is better to have a chessboard with even,
and odd dimension (for example 7$\times$ 8 inner corners) since it has only one
symmetry axis, and the pose of the object can be detected correctly. It is
important that chessboard indeed has squares, not rectangles (so it is better
to check it after printing). A bigger chessboard is easier to recognize, so we
recommend format A4.

We need only one image for computing distortion coefficients. However, for
camera matrix, we need at least two images. For stereo calibration, we need at
least $X$ corresponding images.

We know the minimum number of the images needed for calibration. On the other
hand, we use more images for the robustness of the algorithm. We need a "rich"
set of views. Therefore it is important to move chessboard between images. With
more provided information to the algorithm, it compensates the errors in the
measurements (like a wrongly detected chessboard in one of the images).
Therefore also the computation time increases. Since it is enough for a given
setup of the cameras to perform a calibration only once and then use results
from it again, we recommend to do the calibration on more images and wait a
little bit longer for the results. 


